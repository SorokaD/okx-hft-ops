# ============================================
# Prometheus Configuration for Tumar HFT Infrastructure
# ============================================
# Targets:
#   - Prometheus (self)
#   - Traefik (reverse proxy)
#   - Node Exporter (host metrics)
#   - cAdvisor (container metrics)
#   - Grafana, Loki (monitoring stack)
#   - MinIO (S3 storage)
#   - PostgreSQL databases (via postgres_exporter)
#   - TimescaleDB (external node: 167.86.110.201)
#   - Collector (external node: 217.216.73.20)
# ============================================

global:
  scrape_interval: 15s
  evaluation_interval: 15s
  external_labels:
    cluster: 'tumar-ops'
    env: 'production'

rule_files:
  - /etc/prometheus/alert.rules.yml

# Alertmanager configuration (uncomment when ready)
# alerting:
#   alertmanagers:
#     - static_configs:
#         - targets: ['alertmanager:9093']

scrape_configs:
  # ==================== Self Monitoring ====================
  
  - job_name: 'prometheus'
    static_configs:
      - targets: ['prometheus:9090']
        labels:
          service: 'prometheus'
          node: 'ops'

  # ==================== Infrastructure ====================
  
  - job_name: 'traefik'
    static_configs:
      - targets: ['traefik:8082']
        labels:
          service: 'traefik'
          node: 'ops'

  - job_name: 'node_ops'
    static_configs:
      - targets: ['node-exporter:9100']
        labels:
          service: 'node-exporter'
          node: 'ops'

  - job_name: 'cadvisor_ops'
    static_configs:
      - targets: ['cadvisor:8080']
        labels:
          service: 'cadvisor'
          node: 'ops'

  - job_name: 'docker'
    static_configs:
      - targets: ['host.docker.internal:9323']
        labels:
          service: 'docker'
          node: 'ops'

  # ==================== Monitoring Stack ====================
  
  - job_name: 'grafana'
    metrics_path: /metrics
    static_configs:
      - targets: ['grafana:3000']
        labels:
          service: 'grafana'
          node: 'ops'

  - job_name: 'loki'
    metrics_path: /metrics
    static_configs:
      - targets: ['loki:3100']
        labels:
          service: 'loki'
          node: 'ops'

  # ==================== ML/Data Platform ====================
  
  - job_name: 'minio'
    metrics_path: /minio/v2/metrics/cluster
    static_configs:
      - targets: ['minio:9000']
        labels:
          service: 'minio'
          node: 'ops'

  # MinIO bucket metrics
  - job_name: 'minio_bucket'
    metrics_path: /minio/v2/metrics/bucket
    static_configs:
      - targets: ['minio:9000']
        labels:
          service: 'minio-bucket'
          node: 'ops'

  # ==================== Services without native Prometheus metrics ====================
  # MLflow, Superset, Airflow don't expose /metrics endpoints
  # Their metrics are available via cAdvisor (container CPU, memory, network)
  # 
  # To monitor their health, use:
  # - Blackbox exporter (HTTP probes) - optional, add later if needed
  # - Container metrics from cAdvisor job
  # - Keep-alive service logs in Loki

  # ==================== PostgreSQL Databases (ops node) ====================
  
  - job_name: 'postgres_ops'
    static_configs:
      - targets: ['postgres-exporter:9187']
        labels:
          service: 'postgres-exporter'
          node: 'ops'
          databases: 'mlflow,superset,airflow'

  # ==================== External Nodes ====================
  # NOTE: These require exporters to be running on the target nodes
  # Configure firewall to allow Prometheus (ops) to scrape these ports
  
  # TimescaleDB (collector node)
  # Uncomment when postgres_exporter is configured on 167.86.110.201
  # - job_name: 'postgres_timescale'
  #   static_configs:
  #     - targets: ['167.86.110.201:9187']
  #       labels:
  #         service: 'postgres-exporter'
  #         node: 'timescale'
  #         database: 'okx_hft'

  # Node metrics from TimescaleDB server
  # Uncomment when node_exporter is configured on 167.86.110.201
  # - job_name: 'node_timescale'
  #   static_configs:
  #     - targets: ['167.86.110.201:9100']
  #       labels:
  #         service: 'node-exporter'
  #         node: 'timescale'

  # Collector Python service
  # Uncomment when /metrics endpoint is added to collector on 217.216.73.20
  # - job_name: 'collector'
  #   metrics_path: /metrics
  #   static_configs:
  #     - targets: ['217.216.73.20:8000']
  #       labels:
  #         service: 'collector'
  #         node: 'collector'

  # Node metrics from Collector server
  # Uncomment when node_exporter is configured on 217.216.73.20
  # - job_name: 'node_collector'
  #   static_configs:
  #     - targets: ['217.216.73.20:9100']
  #       labels:
  #         service: 'node-exporter'
  #         node: 'collector'
